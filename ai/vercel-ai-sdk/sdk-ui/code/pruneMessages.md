
# ğŸ¯ pruneMessages() â€” Complete 0â€“100% Guide (Plain English)

## ğŸ¤” What Is It? (Super Simple)

**`pruneMessages()` cleans up chat history before sending it to the AI**  
â†’ fewer tokens, lower cost, faster responses, no internal junk.

```plaintext
BEFORE (Full chat â€” expensive & slow):
â”œâ”€ User: "Hi, how are you?"
â”œâ”€ Assistant: [Internal reasoning: "Let me think..."]
â”œâ”€ Assistant: "I'm good! Let me check the weather"
â”œâ”€ Assistant: [Tool call: GET /weather]
â”œâ”€ Assistant: [Tool result: sunny 72Â°F]
â”œâ”€ Assistant: "The weather is sunny!"
â””â”€ User: "Great, thanks!"
   â†‘ 10 messages sent to AI

AFTER (Pruned):
â”œâ”€ User: "Hi, how are you?"
â”œâ”€ Assistant: "I'm good! Let me check the weather"
â”œâ”€ Assistant: "The weather is sunny!"
â””â”€ User: "Great, thanks!"
   â†‘ 4 messages â†’ Faster & cheaper!
````

---

## âŒ Problems It Solves

* âŒ **Too much context** â†’ higher token cost
* âŒ **Internal reasoning leaks** â†’ confusing & unsafe
* âŒ **Old tool calls** â†’ irrelevant clutter
* âŒ **Token waste** â†’ $$$ burned

---

## ğŸ’¡ Why You Need It

### ğŸ’° The Money Problem

```plaintext
Full chat (100 msgs)   = $1.00 / request
Pruned chat (20 msgs) = $0.20 / request

1000 requests/day:
Without pruning: $1000/day
With pruning:    $200/day
Savings:        $800/day ğŸ’¸
```

---

### ğŸš€ The Speed Problem

```plaintext
Full chat:
- DB load: 200ms
- Send to AI: 500ms
- Processing: 1000ms
TOTAL: 1700ms âŒ

Pruned chat:
- DB load: 50ms
- Send to AI: 100ms
- Processing: 900ms
TOTAL: 1050ms âœ… (~40% faster)
```

---

## ğŸ“ Where & When to Use It

### âœ… USE IT IN THE BACKEND (Before sending to AI)

```ts
// app/api/chat/route.ts
import { pruneMessages, streamText } from 'ai';
import { google } from '@ai-sdk/google';

export async function POST(req: Request) {
  let { messages } = await req.json();

  messages = pruneMessages({
    messages,
    reasoning: 'all',
    toolCalls: 'before-last-message',
    emptyMessages: 'remove',
  });

  const result = await streamText({
    model: google('gemini-2.0-flash'),
    messages,
  });

  return result.toTextStreamResponse();
}
```

---

### âŒ NEVER prune on the frontend

```tsx
// âŒ WRONG
const pruned = pruneMessages(messages);
// Users should see full chat history!
```

---

## ğŸ›ï¸ What Can It Remove?

---

### 1ï¸âƒ£ Reasoning (AI Internal Thoughts)

**Problem**

```plaintext
Assistant:
- "I need to check the weather..."
- "Let me search..."
- "The weather is sunny"
```

**Solution**

```ts
pruneMessages({
  messages,
  reasoning: 'all',
});
```

**Result**

```plaintext
"The weather is sunny"
```

**Options**

* `'none'` (default)
* `'all'`
* `'before-last-message'`

---

### 2ï¸âƒ£ Tool Calls (Function / API Calls)

**Problem**

```plaintext
Old weather searches polluting history
```

**Solution**

```ts
pruneMessages({
  messages,
  toolCalls: 'before-last-message',
});
```

**Options**

* `'none'`
* `'all'`
* `'before-last-message'`
* `'before-last-5-messages'`
* Custom tool filters:

```ts
toolCalls: [{ type: 'all', tools: ['search'] }]
```

---

### 3ï¸âƒ£ Empty Messages

**Problem**

```plaintext
Messages become empty after pruning
```

**Solution**

```ts
pruneMessages({
  messages,
  emptyMessages: 'remove',
});
```

**Options**

* `'remove'` âœ… (default)
* `'keep'` âŒ

---

## ğŸš€ Complete Working Example (Gemini Flash)

```ts
// app/api/chat/route.ts
import {
  convertToModelMessages,
  pruneMessages,
  streamText,
} from 'ai';
import { google } from '@ai-sdk/google';

export async function POST(req: Request) {
  let { messages } = await req.json();

  let modelMessages = await convertToModelMessages(messages);

  modelMessages = pruneMessages({
    messages: modelMessages,
    reasoning: 'all',
    toolCalls: 'before-last-2-messages',
    emptyMessages: 'remove',
  });

  const result = await streamText({
    model: google('gemini-2.0-flash'),
    messages: modelMessages,
  });

  return result.toTextStreamResponse();
}
```

---

## ğŸ”„ How It Works

```plaintext
Frontend (useChat)
â”‚ Full history (with reasoning & tools)
â†“ POST /api/chat
Backend
â”‚ pruneMessages()
â”‚ â”œâ”€ removes reasoning
â”‚ â”œâ”€ removes old tools
â”‚ â””â”€ removes empty messages
â†“
Gemini (clean context)
â†“
Frontend (new message only)
```

---

## ğŸ“‹ All Options Reference

```ts
pruneMessages({
  messages,

  reasoning: 'none' | 'all' | 'before-last-message',

  toolCalls:
    | 'none'
    | 'all'
    | 'before-last-message'
    | 'before-last-3-messages'
    | [{ type: 'all', tools: ['weather'] }],

  emptyMessages: 'remove' | 'keep',
});
```

---

## ğŸ¯ Real-World Scenarios

### Long Conversations

```ts
pruneMessages({
  reasoning: 'all',
  toolCalls: 'before-last-message',
});
```

### Budget-Conscious App

```ts
pruneMessages({
  reasoning: 'all',
  toolCalls: 'all',
});
```

### Deep Reasoning Models

```ts
pruneMessages({
  reasoning: 'before-last-message',
});
```

---

## ğŸ’¡ Pro Tips

âœ… Keep **recent tools**
âŒ Remove **old reasoning**
âŒ Never prune **user messages**
âœ… Prune **only before sending to AI**

---

## ğŸ”• When NOT to Prune

* Saving full history to DB
* Debugging tools
* Auditing model behavior
* Showing users raw reasoning

---

## ğŸ“Š Token Savings Example

```plaintext
Before: 1000 tokens â†’ $0.01
After:  400 tokens  â†’ $0.004
Savings/request: $0.006
10k requests/year = $60 saved ğŸ‰
```

---

## ğŸ‰ Summary (Memorize This)

* **What:** Cleans chat history
* **Where:** Backend only
* **When:** Before sending to AI
* **Why:** Save money + speed
* **How:**

```ts
pruneMessages({ messages, reasoning, toolCalls, emptyMessages });
```

---

## ğŸš€ Quick Reference

| Scenario     | reasoning           | toolCalls              | emptyMessages |
| ------------ | ------------------- | ---------------------- | ------------- |
| Long chat    | all                 | before-last-message    | remove        |
| Budget tight | all                 | all                    | remove        |
| Keep context | before-last-message | before-last-3-messages | remove        |
| Safe default | none                | none                   | remove        |

---

ğŸ’¥ **Thatâ€™s it.**
You now fully understand **`pruneMessages()`** â€” use it to **cut costs, boost speed, and keep AI inputs clean** ğŸš€
